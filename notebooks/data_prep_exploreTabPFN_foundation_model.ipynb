{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e775500f",
   "metadata": {},
   "source": [
    "## Data preparation and Exploring Teacher Models\n",
    "\n",
    "### To make this as multioutput task creating additional continuous target 'max_loan' based on following rule\n",
    "\n",
    "- **'max_loan' to define maximum amount of eligible loan for 'loan_status' == 1 and assign random values between 90000 to 300000 with interval of 5k based on following rules:**\n",
    "\n",
    "1) Generally loan amount is less for the age < 30 as the percieved risk is high, however there is no direct inverse linear relationship\n",
    "2) For working class for equally educated person following is the order of preference from high to low Federal-gov > State-gov > Local-gov > Private  > Self-emp-not-inc > Without-pay > Never-worked\n",
    "3) naturally education-num has positive co-rrelation with maximum amount of eligible loan.\n",
    "4) Based on the occupation make a good judgement about percieved risk and maximum amount of eligible loan. For  example persons with Exec-managerial, Prof-specialty occupation are eligible for higher loan amount than Sales/Adm-clerical. Sales/Adm-clerical are elible for higher loan than people with blue collar jobs like Machine-op-inspct, Farming-fishing etc. Naturally there is a direct relationship between occupation and education-num.\n",
    "5) relationship, race, sex etc. have no connection with maximum amount of eligible loan. So consider them as no influencer.\n",
    "6) net of capital-gain and capital-loss(capital-gain - capital-loss) has generally +ve  co-rrelation with maximum amount of eligible loan.\n",
    "7) hours-per-week generally have no direct co-rrelation with maximum amount of eligible loan. Generally working for less than 35 hours infers not a full time high paying job. At the same time working more than 50 hours may indicate blue collar jobs and hence also not very high paying. consider this this in conjunction with the occupation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.datasets import fetch_adult\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabpfn import TabPFNRegressor, TabPFNClassifier\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "regressor_model = TabPFNRegressor()\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write a suitable docstring for the function below with details of what the function does, its parameters and its return value mentioning max_loan column creation.\n",
    "def getDataset():\n",
    "    \"\"\"\n",
    "    Fetches the Adult dataset and simulates a 'max_loan' column for eligible loan applicants.\n",
    "    The function processes the Adult dataset to identify individuals eligible for loans\n",
    "    (those earning more than 50K) and assigns them a maximum loan amount based on\n",
    "    various demographic and economic factors.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the original Adult dataset features,\n",
    "                      a 'loan_status' column indicating eligibility (1 for >50K, 0 for <=50K),\n",
    "                      and a 'max_loan' column representing the simulated maximum loan amount for eligible applicants.\n",
    "    The 'max_loan' amounts are influenced by factors such as age, workclass, education level,\n",
    "    occupation, capital gains/losses, and hours worked per week\n",
    "    \"\"\"\n",
    "    data = fetch_adult(as_frame=True)\n",
    "    df = data.data\n",
    "    data.target.replace({ \"<=50K\": 0, \">50K\": 1 }, inplace=True)\n",
    "    df['loan_status'] = data.target\n",
    "    \n",
    "    # Create max_loan column only for loan_status == 1\n",
    "    df['max_loan'] = 0\n",
    "    \n",
    "    # Filter for eligible loan applicants (loan_status == 1)\n",
    "    eligible_mask = df['loan_status'] == 1\n",
    "    eligible_df = df[eligible_mask].copy()\n",
    "    \n",
    "    if len(eligible_df) > 0:\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Initialize base loan amounts (90k to 300k in 5k intervals)\n",
    "        loan_amounts = np.arange(90000, 305000, 5000)\n",
    "        base_loans = np.random.choice(loan_amounts, size=len(eligible_df))\n",
    "        \n",
    "        # Apply adjustments based on various factors\n",
    "        loan_adjustments = np.ones(len(eligible_df))\n",
    "        \n",
    "        # 1. Age factor (age < 30 gets lower amounts, but not strictly linear)\n",
    "        age_factor = np.where(eligible_df['age'] < 30, \n",
    "                             np.random.uniform(0.7, 0.9, size=len(eligible_df)),\n",
    "                             np.where(eligible_df['age'] > 50,\n",
    "                                     np.random.uniform(0.9, 1.1, size=len(eligible_df)),\n",
    "                                     np.random.uniform(0.85, 1.05, size=len(eligible_df))))\n",
    "        loan_adjustments *= age_factor\n",
    "        \n",
    "        # 2. Workclass factor (Federal-gov > State-gov > Local-gov > Private > Self-emp-not-inc > Without-pay > Never-worked)\n",
    "        workclass_multipliers = {\n",
    "            'Federal-gov': 1.2,\n",
    "            'State-gov': 1.15,\n",
    "            'Local-gov': 1.1,\n",
    "            'Private': 1.0,\n",
    "            'Self-emp-inc': 0.95,\n",
    "            'Self-emp-not-inc': 0.85,\n",
    "            'Without-pay': 0.6,\n",
    "            'Never-worked': 0.5\n",
    "        }\n",
    "        # Handle categorical workclass properly\n",
    "        workclass_factor = []\n",
    "        for wc in eligible_df['workclass']:\n",
    "            if pd.isna(wc) or wc not in workclass_multipliers:\n",
    "                workclass_factor.append(0.8)  # Default for unknown/missing workclass\n",
    "            else:\n",
    "                workclass_factor.append(workclass_multipliers[wc])\n",
    "        workclass_factor = np.array(workclass_factor)\n",
    "        loan_adjustments *= workclass_factor\n",
    "        \n",
    "        # 3. Education factor (positive correlation with education-num)\n",
    "        education_factor = 0.7 + (eligible_df['education-num'] / 16) * 0.6  # Scale from 0.7 to 1.3\n",
    "        loan_adjustments *= education_factor\n",
    "        \n",
    "        # 4. Occupation factor (risk-based assessment)\n",
    "        occupation_multipliers = {\n",
    "            'Exec-managerial': 1.3,\n",
    "            'Prof-specialty': 1.25,\n",
    "            'Tech-support': 1.1,\n",
    "            'Sales': 1.0,\n",
    "            'Adm-clerical': 0.95,\n",
    "            'Protective-serv': 0.9,\n",
    "            'Craft-repair': 0.85,\n",
    "            'Transport-moving': 0.8,\n",
    "            'Machine-op-inspct': 0.75,\n",
    "            'Other-service': 0.7,\n",
    "            'Farming-fishing': 0.65,\n",
    "            'Handlers-cleaners': 0.6,\n",
    "            'Priv-house-serv': 0.55,\n",
    "            'Armed-Forces': 1.05\n",
    "        }\n",
    "        # Handle categorical occupation properly\n",
    "        occupation_factor = []\n",
    "        for occ in eligible_df['occupation']:\n",
    "            if pd.isna(occ) or occ not in occupation_multipliers:\n",
    "                occupation_factor.append(0.8)  # Default for unknown/missing occupation\n",
    "            else:\n",
    "                occupation_factor.append(occupation_multipliers[occ])\n",
    "        occupation_factor = np.array(occupation_factor)\n",
    "        loan_adjustments *= occupation_factor\n",
    "        \n",
    "        # 6. Capital gain/loss factor (net capital has positive correlation)\n",
    "        net_capital = eligible_df['capital-gain'] - eligible_df['capital-loss']\n",
    "        # Normalize capital gains impact (cap the effect to avoid extreme values)\n",
    "        capital_factor = 1.0 + np.clip(net_capital / 100000, -0.2, 0.3)\n",
    "        loan_adjustments *= capital_factor\n",
    "        \n",
    "        # 7. Hours per week factor (sweet spot around 40-50 hours)\n",
    "        hours_factor = np.where(eligible_df['hours-per-week'] < 35, 0.85,\n",
    "                               np.where(eligible_df['hours-per-week'] > 50, 0.9, 1.0))\n",
    "        loan_adjustments *= hours_factor\n",
    "        \n",
    "        # Apply all adjustments to base loan amounts\n",
    "        final_loans = base_loans * loan_adjustments\n",
    "        \n",
    "        # Round to nearest 5000 and ensure within bounds\n",
    "        final_loans = np.round(final_loans / 5000) * 5000\n",
    "        final_loans = np.clip(final_loans, 90000, 300000)\n",
    "        \n",
    "        # Assign the calculated loan amounts back to the main dataframe\n",
    "        df.loc[eligible_mask, 'max_loan'] = final_loans.astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.DataFrame(getDataset()) \n",
    "print(df.head())\n",
    "print(f\"\\nLoan statistics for eligible applicants:\")\n",
    "print(df[df['loan_status'] == 1]['max_loan'].describe())\n",
    "df.to_csv('../data/loan_data_with_max_loan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423e31d",
   "metadata": {},
   "source": [
    "### 🧠 About TabPFN Foundation Model:\n",
    "\n",
    "A substantial foundation model with over 11 million parameters, trained on diverse structured data to learn general patterns that transfer to new tabular datasets both for regression and classification tasks!\n",
    "\n",
    "- **Pre-trained** on millions of synthetic tabular datasets\n",
    "- **Transformer-based** architecture optimized for tabular data\n",
    "- **Foundation model** that can adapt to new tasks with minimal data\n",
    "- **Ensemble approach** uses multiple models for robust predictions\n",
    "- **Efficient** for small datasets (≤10K samples)\n",
    "\n",
    "- **More details is here :**\n",
    "https://github.com/PriorLabs/TabPFN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7d0cc",
   "metadata": {},
   "source": [
    "- **Sneak peek Teacher Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data to fit the model (this will load the underlying PyTorch model)\n",
    "print(\"Creating dummy data and fitting the model...\")\n",
    "X_dummy, y_dummy = make_regression(n_samples=100, n_features=5, random_state=42)\n",
    "\n",
    "# Fit the model - this will load the underlying PyTorch model\n",
    "regressor_model.fit(X_dummy, y_dummy)\n",
    "\n",
    "print(\"Model fitted! Now analyzing the TabPFN model parameters...\")\n",
    "\n",
    "# Get the underlying PyTorch model\n",
    "model = regressor_model.model_\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABPFN REGRESSOR MODEL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\" Model Architecture: {model.__class__.__name__}\")\n",
    "print(f\" Total Parameters: {total_params:,}\")\n",
    "print(f\" Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\" Model Size: {(total_params * 4) / (1024**2):.2f} MB\")\n",
    "\n",
    "print(f\"\\n Ensemble Configuration:\")\n",
    "print(f\"   Number of estimators: {regressor_model.n_estimators}\")\n",
    "print(f\"   Total ensemble parameters: {total_params * regressor_model.n_estimators:,}\")\n",
    "\n",
    "# Show parameter distribution by layer type\n",
    "layer_counts = {}\n",
    "for name, param in model.named_parameters():\n",
    "    layer_type = name.split('.')[0]\n",
    "    layer_counts[layer_type] = layer_counts.get(layer_type, 0) + param.numel()\n",
    "\n",
    "print(f\"\\n Parameter Distribution:\")\n",
    "for layer_type, count in sorted(layer_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (count / total_params) * 100\n",
    "    print(f\"   {layer_type}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to get TabPFN parameter count\n",
    "def get_tabpfn_parameter_count(model_type='regressor'):\n",
    "    \"\"\"\n",
    "    Get the parameter count of a TabPFN model without fitting data.\n",
    "    \n",
    "    Args:\n",
    "        model_type (str): 'regressor' or 'classifier'\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing parameter information\n",
    "    \"\"\"\n",
    "    \n",
    "    # Choose the appropriate model and dummy data\n",
    "    if model_type.lower() == 'regressor':\n",
    "        model = TabPFNRegressor()\n",
    "        X_dummy, y_dummy = make_regression(n_samples=50, n_features=5, random_state=42)\n",
    "    else:\n",
    "        model = TabPFNClassifier()\n",
    "        X_dummy, y_dummy = make_classification(n_samples=50, n_features=5, n_classes=2, random_state=42)\n",
    "    \n",
    "    # Fit with minimal data to load the model\n",
    "    model.fit(X_dummy, y_dummy)\n",
    "    \n",
    "    # Get parameter count\n",
    "    pytorch_model = model.model_\n",
    "    total_params = sum(p.numel() for p in pytorch_model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in pytorch_model.parameters() if p.requires_grad)\n",
    "    \n",
    "    return {\n",
    "        'model_type': model_type,\n",
    "        'architecture': pytorch_model.__class__.__name__,\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params,\n",
    "        'model_size_mb': (total_params * 4) / (1024**2),\n",
    "        'n_estimators': model.n_estimators,\n",
    "        'ensemble_total_params': total_params * model.n_estimators\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "print(\"Getting TabPFN parameter information...\")\n",
    "regressor_info = get_tabpfn_parameter_count('regressor')\n",
    "classifier_info = get_tabpfn_parameter_count('classifier')\n",
    "\n",
    "print(\"\\n TABPFN PARAMETER SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Regressor Parameters: {regressor_info['total_parameters']:,}\")\n",
    "print(f\"Classifier Parameters: {classifier_info['total_parameters']:,}\")\n",
    "print(f\"Architecture: {regressor_info['architecture']}\")\n",
    "print(f\"Single Model Size: {regressor_info['model_size_mb']:.1f} MB\")\n",
    "print(f\"Default Ensemble Size: {regressor_info['n_estimators']} models\")\n",
    "print(f\"Total Ensemble Parameters: {regressor_info['ensemble_total_params']:,}\")\n",
    "\n",
    "print(f\"\\n Answer to your question:\")\n",
    "print(f\"The TabPFN foundation model has {regressor_info['total_parameters']:,} parameters\")\n",
    "print(f\"When used as an ensemble (default), it uses {regressor_info['ensemble_total_params']:,} total parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b993d",
   "metadata": {},
   "source": [
    "## 🔍 TabPFN Model Parameters - Summary\n",
    "\n",
    "\n",
    "### 📊 Key Findings:\n",
    "\n",
    "1. **TabPFNRegressor**: **11,081,864 parameters** (~11.1M)\n",
    "2. **TabPFNClassifier**: **7,244,554 parameters** (~7.2M) \n",
    "3. **Architecture**: PerFeatureTransformer (Transformer-based)\n",
    "4. **Model Size**: ~42.3 MB per model\n",
    "5. **Ensemble**: 8 models by default = **88,654,912 total parameters**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee314d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
