{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b376d8",
   "metadata": {},
   "source": [
    "# üè¶ LLM-Powered What-If Analysis for Loan Approvals\n",
    "\n",
    "#### This notebook implements an intelligent loan approval system that combines machine learning with natural language processing to enable dynamic \"what-if\" scenario analysis. Instead of static rule-based assessments, loan officers can explore hypothetical scenarios using natural language:\n",
    "\n",
    "> \"What if the customer had a Masters degree and 5 years more work experience?\"  \n",
    "> \"What would be the maximum loan amount if they switched to an executive role?\"\n",
    "\n",
    "## Key Features\n",
    "\n",
    "üß† **Intelligent Scenario Processing**\n",
    "- Natural language understanding of complex scenarios\n",
    "- Automatic translation of scenarios into feature modifications\n",
    "- Real-time validation against historical data patterns\n",
    "\n",
    "üîí **Privacy-Preserving Architecture**\n",
    "- Session-based customer context management\n",
    "- Secure handling of sensitive financial data\n",
    "- Clear context boundaries between customers\n",
    "\n",
    "üìä **Dynamic Impact Analysis**\n",
    "- Real-time loan approval probability changes\n",
    "- Automated loan amount recalculation\n",
    "- Visual indicators for positive/negative impacts (‚ÜóÔ∏è/‚ÜòÔ∏è)\n",
    "\n",
    "The system helps financial institutions make more informed lending decisions by understanding the impact of potential changes in a customer's profile, while maintaining data privacy and security throughout the analysis process.### üìö Setup and Dependencies\n",
    "This cell sets up the core infrastructure for our loan approval system:\n",
    "- Configures Python path and imports required libraries\n",
    "- Sets up Azure OpenAI credentials for LLM integration\n",
    "- Initializes the GPT-4 model for natural language processing\n",
    "- Imports custom prediction utilities for loan analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67859b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI endpoint: https://souri-mf5naon1-eastus2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import importlib\n",
    "sys.path.append('/Users/sourishdey/Desktop/learning/model_distillation/model_distillation')\n",
    "\n",
    "# Core imports\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "# Import prediction utilities\n",
    "import prediction_utils\n",
    "importlib.reload(prediction_utils)\n",
    "from prediction_utils import (\n",
    "    LoanPredictionService, \n",
    "    predict_customer_loan_propensity,\n",
    "    predict_customer_loan_amount,\n",
    "    get_prediction_service\n",
    ")\n",
    "\n",
    "# Setup Azure OpenAI credentials\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"<your_api_key>\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"<your_endpoint>\"\n",
    "\n",
    "print(f\"Using Azure OpenAI endpoint: {os.environ['AZURE_OPENAI_ENDPOINT']}\")\n",
    "\n",
    "# Setup the LLM\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4.1-nano\",\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    model=\"gpt-4.1-nano\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f9c40",
   "metadata": {},
   "source": [
    "### üîß Core Data Tools and Utilities\n",
    "This cell implements essential data management functionality:\n",
    "- Global data storage for customer information\n",
    "- CSV data loading tool with error handling\n",
    "- Customer information retrieval with validation\n",
    "- JSON serialization utility for consistent data formatting\n",
    "These tools form the foundation for all customer data operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bdd57ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable for data storage\n",
    "_loaded_data = None\n",
    "\n",
    "@tool\n",
    "def load_data(path: str = \"/Users/sourishdey/Desktop/learning/model_distillation/model_distillation/data/business_simulation.csv\") -> str:\n",
    "    \"\"\"Load the loan dataset from a CSV file.\"\"\"\n",
    "    global _loaded_data\n",
    "    # Force absolute path to avoid FileNotFoundError\n",
    "    abs_path = \"/Users/sourishdey/Desktop/learning/model_distillation/model_distillation/data/business_simulation.csv\"\n",
    "    _loaded_data = pd.read_csv(abs_path)\n",
    "    return f\"Successfully loaded dataset with {len(_loaded_data)} customers\"\n",
    "\n",
    "@tool\n",
    "def get_customer_information(customer_id: int) -> str:\n",
    "    \"\"\"Get customer information including current loan status.\"\"\"\n",
    "    global _loaded_data\n",
    "    if '_loaded_data' not in globals() or _loaded_data is None:\n",
    "        return \"Error: Data not loaded. Please call load_data first.\"\n",
    "    \n",
    "    customer_info = _loaded_data[_loaded_data['customer_id'] == customer_id]\n",
    "    if customer_info.empty:\n",
    "        # Fallback to valid customer IDs if the requested one doesn't exist\n",
    "        valid_ids = _loaded_data['customer_id'].head(5).tolist()\n",
    "        return f\"Error: Customer ID {customer_id} not found. Valid IDs (first 5): {valid_ids}\"\n",
    "    \n",
    "    return customer_info.to_json(orient='records', indent=2)\n",
    "\n",
    "def _make_json_serializable(obj):\n",
    "    \"\"\"Convert objects to JSON-serializable types.\"\"\"\n",
    "    import numpy as np\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _make_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [_make_json_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, (np.integer, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "@tool\n",
    "def load_predict_loan_approval_propensity(customer_id: int) -> str:\n",
    "    \"\"\"Fast loan approval propensity prediction.\"\"\"\n",
    "    global _loaded_data\n",
    "    if '_loaded_data' not in globals() or _loaded_data is None:\n",
    "        return \"Error: Data not loaded. Please call load_data first.\"\n",
    "    \n",
    "    # Initialize prediction service if needed\n",
    "    prediction_service = get_prediction_service()\n",
    "    \n",
    "    # Make prediction\n",
    "    result = predict_customer_loan_propensity(_loaded_data, customer_id, prediction_service)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        return str(result)\n",
    "    \n",
    "    # Convert to JSON-serializable format\n",
    "    result = _make_json_serializable(result)\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "@tool   \n",
    "def load_predict_loan_amount(customer_id: int) -> str:\n",
    "    \"\"\"Predict loan amount for a specific customer using simplified calculation.\"\"\"\n",
    "    global _loaded_data\n",
    "    if '_loaded_data' not in globals() or _loaded_data is None:\n",
    "        return \"Error: Data not loaded. Please call load_data first.\"\n",
    "    \n",
    "    customer_data = _loaded_data.loc[_loaded_data['customer_id'] == customer_id]\n",
    "    if customer_data.empty:\n",
    "        valid_ids = _loaded_data['customer_id'].head(5).tolist()\n",
    "        return f\"Error: Customer ID {customer_id} not found. Valid IDs: {valid_ids}\"\n",
    "    \n",
    "    # Get approval probability first\n",
    "    prediction_service = get_prediction_service()\n",
    "    approval_result = prediction_service.predict_single_customer(customer_data)\n",
    "    \n",
    "    # Calculate loan amount based on approval probability and customer profile\n",
    "    if approval_result['approved']:\n",
    "        # Base amount on probability and some customer factors\n",
    "        base_amount = approval_result['loan_approval_probability'] * 50000\n",
    "        \n",
    "        # Adjust based on customer characteristics\n",
    "        customer_row = customer_data.iloc[0]\n",
    "        \n",
    "        # Education bonus\n",
    "        if customer_row.get('education', '') in ['Masters', 'Doctorate']:\n",
    "            base_amount *= 1.2\n",
    "        elif customer_row.get('education', '') in ['Bachelors']:\n",
    "            base_amount *= 1.1\n",
    "            \n",
    "        # Age factor (middle-aged customers might get higher amounts)\n",
    "        age = customer_row.get('age', 25)\n",
    "        if 30 <= age <= 50:\n",
    "            base_amount *= 1.1\n",
    "            \n",
    "        # Capital gain bonus\n",
    "        capital_gain = customer_row.get('capital-gain', 0)\n",
    "        if capital_gain > 5000:\n",
    "            base_amount *= 1.3\n",
    "        elif capital_gain > 0:\n",
    "            base_amount *= 1.1\n",
    "            \n",
    "        predicted_amount = min(base_amount, 75000)  # Cap at $75k\n",
    "    else:\n",
    "        predicted_amount = 0.0\n",
    "    \n",
    "    result = {\n",
    "        'customer_id': customer_id,\n",
    "        'loan_approval_probability': approval_result['loan_approval_probability'],\n",
    "        'approved': approval_result['approved'],\n",
    "        'predicted_loan_amount': predicted_amount,\n",
    "        'calculation_method': 'Heuristic based on approval probability and customer profile'\n",
    "    }\n",
    "    \n",
    "    # Convert to JSON-serializable format\n",
    "    result = _make_json_serializable(result)\n",
    "    return json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc21100",
   "metadata": {},
   "source": [
    "### üéØ Intelligent What-If Analysis Tools\n",
    "This cell implements the core scenario analysis functionality:\n",
    "- Natural language scenario parsing using GPT-4\n",
    "- Dynamic feature modification based on customer data\n",
    "- Automated type conversion and validation\n",
    "- Baseline vs. scenario comparison metrics\n",
    "- Real-time probability change visualization (‚ÜóÔ∏è/‚ÜòÔ∏è)\n",
    "These tools enable sophisticated \"what-if\" analysis for loan approvals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147a63e",
   "metadata": {},
   "source": [
    "# üîÑ LoanSimulatorAgent Architecture\n",
    "\n",
    "The LoanSimulatorAgent uses LangGraph's StateGraph to manage conversation flow and tool execution:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Input] --> B[Entry Point: loan_simulator_llm]\n",
    "    B --> C{should_call_tools?}\n",
    "    C -->|Has tool calls| D[loan_simulator_tools]\n",
    "    C -->|No tool calls| E[END]\n",
    "    D --> F[Execute Tools]\n",
    "    F --> G{More processing?}\n",
    "    G -->|Yes| B\n",
    "    G -->|No| E\n",
    "    \n",
    "    subgraph \"State Management\"\n",
    "        H[LoanSimulatorAgentState]\n",
    "        I[messages: List[AnyMessage]]\n",
    "        H --- I\n",
    "    end\n",
    "    \n",
    "    subgraph \"Tool Integration\"\n",
    "        J[Bind Tools]\n",
    "        K[JSON Response]\n",
    "        L[Customer Context]\n",
    "        J --- K\n",
    "        J --- L\n",
    "    end\n",
    "```\n",
    "\n",
    "ASCII Architecture Diagram:\n",
    "```\n",
    "+----------------------------------------------------------------------------------------+\n",
    "|                                  LoanSimulatorAgent                                     |\n",
    "+----------------------------------------------------------------------------------------+\n",
    "                                         |\n",
    "                                         v\n",
    "+----------------------------------------------------------------------------------------+\n",
    "|                               Privacy-Aware Session                                      |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|  | User Message   |->| State Management |->| Tool Routing  |->| Response Generation |   |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|          ^                    |                   |                     |               |\n",
    "|          |                    v                   v                     v               |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|  | Memory Saver   |  | Message History  |  | Tool Registry |  | JSON Serialization |   |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|                              |                   |                     |               |\n",
    "|                              v                   v                     v               |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|  | Context Reset  |  | Tool Execution   |  | Error Handling|  | Format Validation   |   |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "+----------------------------------------------------------------------------------------+\n",
    "                                         |\n",
    "                                         v\n",
    "+----------------------------------------------------------------------------------------+\n",
    "|                                    Tool Layer                                           |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "|  | Data Loading   |  | What-If Analysis |  | Predictions   |  | Customer Info       |   |\n",
    "|  +----------------+  +------------------+  +----------------+  +---------------------+   |\n",
    "+----------------------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "**Key Components:**\n",
    "1. **State Management**: Tracks conversation context and messages\n",
    "2. **Node Routing**: Intelligent routing between LLM and tool execution\n",
    "3. **Tool Integration**: Dynamic binding of loan-related tools\n",
    "4. **Privacy Boundaries**: Session-based customer context isolation\n",
    "5. **Memory Checkpointing**: Persistent conversation state across interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c647697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def load_predict_loan_approval_whatif(customer_id: int, scenario_description: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Predict loan approval with intelligent natural language scenario modifications.\n",
    "    Uses LLM to dynamically modify customer data based on scenario description.\n",
    "    \"\"\"\n",
    "    global _loaded_data\n",
    "    if '_loaded_data' not in globals() or _loaded_data is None:\n",
    "        return \"Error: Data not loaded. Please call load_data first.\"\n",
    "    \n",
    "    # Get customer data\n",
    "    customer_data = _loaded_data.loc[_loaded_data['customer_id'] == customer_id]\n",
    "    if customer_data.empty:\n",
    "        valid_ids = _loaded_data['customer_id'].head(5).tolist()\n",
    "        return f\"Error: Customer ID {customer_id} not found. Valid IDs: {valid_ids}\"\n",
    "    \n",
    "    modified_data = customer_data.copy()\n",
    "    modifications_applied = []\n",
    "    \n",
    "    # If no scenario, return baseline\n",
    "    if not scenario_description or not scenario_description.strip():\n",
    "        prediction_service = get_prediction_service()\n",
    "        result = prediction_service.predict_single_customer(customer_data)\n",
    "        if \"error\" in result:\n",
    "            return str(result)\n",
    "        \n",
    "        result = _make_json_serializable(result)\n",
    "        result['customer_id'] = customer_id\n",
    "        result['scenario_description'] = \"baseline\"\n",
    "        result['modifications_applied'] = []\n",
    "        return json.dumps(result, indent=2)\n",
    "    \n",
    "    # LLM-powered data modification\n",
    "    try:\n",
    "        # Get dataset structure\n",
    "        column_info = {}\n",
    "        for col in _loaded_data.columns:\n",
    "            if col not in ['customer_id', 'loan_status', 'max_loan']:\n",
    "                if _loaded_data[col].dtype == 'object':\n",
    "                    unique_vals = list(_loaded_data[col].unique())\n",
    "                    column_info[col] = {'type': 'categorical', 'values': unique_vals[:10]}\n",
    "                else:\n",
    "                    column_info[col] = {\n",
    "                        'type': 'numerical',\n",
    "                        'min': float(_loaded_data[col].min()),\n",
    "                        'max': float(_loaded_data[col].max()),\n",
    "                        'current': float(customer_data[col].iloc[0])\n",
    "                    }\n",
    "        \n",
    "        # Create LLM prompt for parsing\n",
    "        modification_prompt = f\"\"\"\n",
    "Analyze this scenario and determine feature modifications for a loan customer.\n",
    "\n",
    "CURRENT DATA: {customer_data.iloc[0].to_dict()}\n",
    "AVAILABLE FEATURES: {json.dumps(column_info, indent=2)}\n",
    "SCENARIO: \"{scenario_description}\"\n",
    "\n",
    "Return JSON with modifications:\n",
    "{{\n",
    "    \"modifications\": {{\n",
    "        \"column_name\": \"new_value\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use exact column names from available features\n",
    "- For categorical: use values from the available list\n",
    "- For numerical: use reasonable values within range\n",
    "- Only modify explicitly mentioned features\n",
    "\"\"\"\n",
    "        \n",
    "        # Parse with LLM\n",
    "        llm_response = model.invoke([HumanMessage(content=modification_prompt)])\n",
    "        llm_content = llm_response.content.strip()\n",
    "        \n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', llm_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            modification_data = json.loads(json_match.group())\n",
    "            \n",
    "            if 'modifications' in modification_data:\n",
    "                for column, new_value in modification_data['modifications'].items():\n",
    "                    if column in modified_data.columns:\n",
    "                        # Apply type conversion\n",
    "                        if _loaded_data[column].dtype == 'object':\n",
    "                            modified_data.loc[:, column] = str(new_value)\n",
    "                        elif 'int' in str(_loaded_data[column].dtype):\n",
    "                            modified_data.loc[:, column] = int(new_value)\n",
    "                        elif 'float' in str(_loaded_data[column].dtype):\n",
    "                            modified_data.loc[:, column] = float(new_value)\n",
    "                        else:\n",
    "                            modified_data.loc[:, column] = new_value\n",
    "                        \n",
    "                        modifications_applied.append(f\"{column}={new_value}\")\n",
    "                        \n",
    "                        if len(modifications_applied) > 10:\n",
    "                            break\n",
    "        \n",
    "    except Exception:\n",
    "        pass  # Use baseline data if parsing fails\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction_service = get_prediction_service()\n",
    "    baseline_result = prediction_service.predict_single_customer(customer_data)\n",
    "    result = prediction_service.predict_single_customer(modified_data)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        return str(result)\n",
    "    \n",
    "    # Format results\n",
    "    result = _make_json_serializable(result)\n",
    "    result['customer_id'] = customer_id\n",
    "    result['scenario_description'] = scenario_description\n",
    "    result['modifications_applied'] = modifications_applied\n",
    "    result['baseline_loan_approval_probability'] = baseline_result['loan_approval_probability']\n",
    "    result['new_loan_approval_probability'] = result['loan_approval_probability']\n",
    "    # Format probability change with arrow and percentage\n",
    "    prob_change = result['loan_approval_probability'] - baseline_result['loan_approval_probability']\n",
    "    arrow = \"‚ÜóÔ∏è\" if prob_change > 0 else \"‚ÜòÔ∏è\" if prob_change < 0 else \"‚û°Ô∏è\"\n",
    "    result['probability_change'] = f\"{arrow} {prob_change:+.1%}\"\n",
    "    \n",
    "\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "@tool   \n",
    "def load_predict_loan_amount_whatif(customer_id: int, scenario_description: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Predict loan amount with intelligent natural language scenario modifications.\n",
    "    Uses LLM to dynamically modify customer data based on scenario description.\n",
    "    \"\"\"\n",
    "    global _loaded_data\n",
    "    if '_loaded_data' not in globals() or _loaded_data is None:\n",
    "        return \"Error: Data not loaded. Please call load_data first.\"\n",
    "    \n",
    "    customer_data = _loaded_data.loc[_loaded_data['customer_id'] == customer_id]\n",
    "    if customer_data.empty:\n",
    "        valid_ids = _loaded_data['customer_id'].head(5).tolist()\n",
    "        return f\"Error: Customer ID {customer_id} not found. Valid IDs: {valid_ids}\"\n",
    "    \n",
    "    modified_data = customer_data.copy()\n",
    "    modifications_applied = []\n",
    "    \n",
    "    # Apply same LLM parsing logic as approval function\n",
    "    if scenario_description and scenario_description.strip():\n",
    "        try:\n",
    "            column_info = {}\n",
    "            for col in _loaded_data.columns:\n",
    "                if col not in ['customer_id', 'loan_status', 'max_loan']:\n",
    "                    if _loaded_data[col].dtype == 'object':\n",
    "                        unique_vals = list(_loaded_data[col].unique())\n",
    "                        column_info[col] = {'type': 'categorical', 'values': unique_vals[:10]}\n",
    "                    else:\n",
    "                        column_info[col] = {\n",
    "                            'type': 'numerical',\n",
    "                            'min': float(_loaded_data[col].min()),\n",
    "                            'max': float(_loaded_data[col].max()),\n",
    "                            'current': float(customer_data[col].iloc[0])\n",
    "                        }\n",
    "            \n",
    "            modification_prompt = f\"\"\"\n",
    "CURRENT DATA: {customer_data.iloc[0].to_dict()}\n",
    "FEATURES: {json.dumps(column_info, indent=2)}\n",
    "SCENARIO: \"{scenario_description}\"\n",
    "\n",
    "Return JSON: {{\"modifications\": {{\"column_name\": \"new_value\"}}}}\n",
    "\"\"\"\n",
    "            \n",
    "            llm_response = model.invoke([HumanMessage(content=modification_prompt)])\n",
    "            llm_content = llm_response.content.strip()\n",
    "            \n",
    "            import re\n",
    "            json_match = re.search(r'\\{.*\\}', llm_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                modification_data = json.loads(json_match.group())\n",
    "                \n",
    "                if 'modifications' in modification_data:\n",
    "                    for column, new_value in modification_data['modifications'].items():\n",
    "                        if column in modified_data.columns:\n",
    "                            if _loaded_data[column].dtype == 'object':\n",
    "                                modified_data.loc[:, column] = str(new_value)\n",
    "                            elif 'int' in str(_loaded_data[column].dtype):\n",
    "                                modified_data.loc[:, column] = int(new_value)\n",
    "                            elif 'float' in str(_loaded_data[column].dtype):\n",
    "                                modified_data.loc[:, column] = float(new_value)\n",
    "                            else:\n",
    "                                modified_data.loc[:, column] = new_value\n",
    "                            \n",
    "                            modifications_applied.append(f\"{column}={new_value}\")\n",
    "                            \n",
    "                            if len(modifications_applied) > 10:\n",
    "                                break\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Make predictions using the prediction service\n",
    "    prediction_service = get_prediction_service()\n",
    "    baseline_approval = prediction_service.predict_single_customer(customer_data)\n",
    "    approval_result = prediction_service.predict_single_customer(modified_data)\n",
    "    \n",
    "    # Calculate loan amounts based on approval probability\n",
    "    # Use a simple heuristic: higher probability = higher loan amount\n",
    "    baseline_loan_amount = 0.0\n",
    "    predicted_loan_amount = 0.0\n",
    "    \n",
    "    if baseline_approval['approved']:\n",
    "        # Use probability to estimate loan amount (simplified calculation)\n",
    "        baseline_loan_amount = baseline_approval['loan_approval_probability'] * 50000  # Max loan ~$50k\n",
    "    \n",
    "    if approval_result['approved']:\n",
    "        predicted_loan_amount = approval_result['loan_approval_probability'] * 50000\n",
    "    \n",
    "    result = {\n",
    "        'customer_id': customer_id,\n",
    "        'loan_approval_probability': approval_result['loan_approval_probability'],\n",
    "        'approved': approval_result['approved'],\n",
    "        'predicted_loan_amount': predicted_loan_amount,\n",
    "        'baseline_loan_amount': baseline_loan_amount,\n",
    "        'scenario_description': scenario_description,\n",
    "        'modifications_applied': modifications_applied,\n",
    "        'reason': 'Loan amount calculated based on approval probability' if approval_result['approved'] else 'Loan rejected due to low approval probability'\n",
    "    }\n",
    "\n",
    "    # Add change calculations\n",
    "    result = _make_json_serializable(result)\n",
    "    result['baseline_loan_approval_probability'] = baseline_approval['loan_approval_probability']\n",
    "    result['new_loan_approval_probability'] = result['loan_approval_probability']\n",
    "    # Format probability change with arrow and percentage\n",
    "    prob_change = result['loan_approval_probability'] - baseline_approval['loan_approval_probability']\n",
    "    arrow = \"‚ÜóÔ∏è\" if prob_change > 0 else \"‚ÜòÔ∏è\" if prob_change < 0 else \"‚û°Ô∏è\"\n",
    "    result['probability_change'] = f\"{arrow} {prob_change:+.1%}\"\n",
    "    result['loan_amount_change'] = f\"+{result['predicted_loan_amount'] - result['baseline_loan_amount']:.2f}\"\n",
    "\n",
    "    return json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c6dfc",
   "metadata": {},
   "source": [
    "### üîí Privacy-Aware Agent Implementation\n",
    "This cell defines the intelligent loan agent architecture:\n",
    "- State management for conversation context\n",
    "- Tool integration with LangGraph framework\n",
    "- Privacy-preserving session handling\n",
    "- Dynamic tool routing and execution\n",
    "- Structured JSON response formatting\n",
    "This implementation ensures secure and contextual loan analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fa53f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîí PRIVACY-AWARE LOAN AGENT\n",
    "\n",
    "class LoanSimulatorAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class LoanSimulatorAgent(StateGraph[LoanSimulatorAgentState]): \n",
    "    def __init__(self, model, tools, system_prompt):\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.system_prompt = system_prompt\n",
    "        \n",
    "        self.model_with_tools = self.model.bind_tools(list(tools.values()))\n",
    "\n",
    "        super().__init__(LoanSimulatorAgentState)\n",
    "        self.add_node(\"loan_simulator_llm\", self.call_llm)\n",
    "        self.add_node(\"loan_simulator_tools\", self.call_tools)\n",
    "        \n",
    "        self.set_entry_point(\"loan_simulator_llm\")\n",
    "        self.add_conditional_edges(\n",
    "            \"loan_simulator_llm\",\n",
    "            self.should_call_tools,\n",
    "            {\"tools\": \"loan_simulator_tools\", \"end\": END}\n",
    "        )\n",
    "        self.add_conditional_edges(\n",
    "            \"loan_simulator_tools\", \n",
    "            lambda state: \"continue\",\n",
    "            {\"continue\": \"loan_simulator_llm\"}\n",
    "        )\n",
    "        \n",
    "        self.agent_graph = self.compile(checkpointer=MemorySaver())\n",
    "\n",
    "    def call_llm(self, state: LoanSimulatorAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system_prompt:\n",
    "            messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "        result = self.model_with_tools.invoke(messages)\n",
    "        return {\"messages\": [result]}\n",
    "\n",
    "    def should_call_tools(self, state: LoanSimulatorAgentState):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and len(last_message.tool_calls) > 0:\n",
    "            return \"tools\"\n",
    "        return \"end\"\n",
    "\n",
    "    def call_tools(self, state: LoanSimulatorAgentState):\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        for tool in tool_calls:\n",
    "            if tool[\"name\"] not in self.tools:\n",
    "                result = f\"Invalid tool '{tool['name']}'\"\n",
    "            else:\n",
    "                result = self.tools[tool[\"name\"]].invoke(tool[\"args\"])\n",
    "\n",
    "            results.append(ToolMessage(\n",
    "                tool_call_id=tool['id'], \n",
    "                name=tool['name'], \n",
    "                content=str(result)\n",
    "            ))\n",
    "\n",
    "        return {\"messages\": results}\n",
    "\n",
    "class PrivacyAwareLoanAgent:\n",
    "    def __init__(self, model, tools):\n",
    "        self.current_customer_id = None\n",
    "        self.memory = MemorySaver()\n",
    "        \n",
    "        self.system_prompt = \"\"\"You are a professional loan analysis chatbot.\n",
    "\n",
    "WORKFLOW:\n",
    "1. Call 'load_data()' once at session start\n",
    "2. Use tools:\n",
    "   - 'get_customer_information(customer_id)' for customer details\n",
    "   - 'load_predict_loan_approval_whatif(customer_id, scenario_description)' for what-if scenarios\n",
    "   - 'load_predict_loan_amount_whatif(customer_id, scenario_description)' for loan amounts\n",
    "\n",
    "WHAT-IF ANALYSIS:\n",
    "- Use natural language descriptions: \"customer has masters degree and is married\"\n",
    "- Tools will intelligently parse and apply modifications\n",
    "- Always use whatif tools for hypothetical scenarios\n",
    "\n",
    "CONTEXT AWARENESS:\n",
    "- Remember previous scenario modifications within the same customer session\n",
    "- When asked about loan amounts after a what-if scenario, use the modified customer profile from the last scenario\n",
    "- If user asks about \"this customer\" or \"maximum loan amount\" after a scenario, apply the previous modifications\n",
    "- Use whatif tools with the last scenario description to maintain consistency\n",
    "\n",
    "JSON OUTPUT FORMAT:\n",
    "{\n",
    "  \"customer_id\": 123,\n",
    "  \"scenario\": \"customer has masters degree\",\n",
    "  \"modifications_applied\": [\"education=Masters\"],\n",
    "  \"new_loan_approval_probability\": 0.72,\n",
    "  \"baseline_loan_approval_probability\": 0.49,\n",
    "  \"probability_change\": \"‚ÜóÔ∏è +23.0%\",\n",
    "  \"approved\": true\n",
    "}\n",
    "\n",
    "RULES:\n",
    "- ALL responses MUST be in valid JSON format only, no additional text\n",
    "- Remember customer context and scenario modifications for follow-up questions\n",
    "- Privacy: clear context when switching customers\n",
    "- Return ONLY the JSON, nothing else\n",
    "\"\"\"\n",
    "        \n",
    "        self.agent = LoanSimulatorAgent(model, tools, self.system_prompt)\n",
    "    \n",
    "    def chat(self, user_message):\n",
    "        import re\n",
    "        \n",
    "        customer_id_match = re.search(r'customer\\s+(\\d+)', user_message, re.IGNORECASE)\n",
    "        mentioned_customer_id = None\n",
    "        \n",
    "        if customer_id_match:\n",
    "            mentioned_customer_id = int(customer_id_match.group(1))\n",
    "            \n",
    "        if not mentioned_customer_id and self.current_customer_id:\n",
    "            mentioned_customer_id = self.current_customer_id\n",
    "            session_id = f\"customer_{mentioned_customer_id}\"\n",
    "        elif mentioned_customer_id:\n",
    "            # Use consistent session ID for the same customer to maintain context\n",
    "            session_id = f\"customer_{mentioned_customer_id}\"\n",
    "            self.current_customer_id = mentioned_customer_id\n",
    "        else:\n",
    "            session_id = \"default_session\"\n",
    "        \n",
    "        result = self.agent.agent_graph.invoke(\n",
    "            {\"messages\": [HumanMessage(content=user_message)]},\n",
    "            config={\"configurable\": {\"thread_id\": session_id}}\n",
    "        )\n",
    "        \n",
    "        final_message = result[\"messages\"][-1]\n",
    "        return final_message.content\n",
    "\n",
    "# Create privacy-aware agent\n",
    "privacy_agent = PrivacyAwareLoanAgent(\n",
    "    model=model,\n",
    "    tools={\n",
    "        \"load_data\": load_data, \n",
    "        \"get_customer_information\": get_customer_information,\n",
    "        \"load_predict_loan_approval_propensity\": load_predict_loan_approval_propensity,\n",
    "        \"load_predict_loan_amount\": load_predict_loan_amount,\n",
    "        \"load_predict_loan_approval_whatif\": load_predict_loan_approval_whatif,\n",
    "        \"load_predict_loan_amount_whatif\": load_predict_loan_amount_whatif\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2f599",
   "metadata": {},
   "source": [
    "### üöÄ Interactive Demo and Testing\n",
    "This cell demonstrates the complete system in action:\n",
    "- Creates a demo agent with all tools\n",
    "- Tests three key scenarios:\n",
    "  1. Basic customer information retrieval\n",
    "  2. Complex what-if scenario analysis\n",
    "  3. Maximum loan amount calculation\n",
    "- Shows real-time responses and modifications\n",
    "Use this cell to validate the entire workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22321705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Get information for customer 12762\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"age\": 25,\n",
      "  \"workclass\": \"Private\",\n",
      "  \"fnlwgt\": 166977,\n",
      "  \"education\": \"Bachelors\",\n",
      "  \"education-num\": 13,\n",
      "  \"marital-status\": \"Married-civ-spouse\",\n",
      "  \"occupation\": \"Prof-specialty\",\n",
      "  \"relationship\": \"Wife\",\n",
      "  \"race\": \"White\",\n",
      "  \"sex\": \"Female\",\n",
      "  \"capital-gain\": 0,\n",
      "  \"capital-loss\": 1887,\n",
      "  \"hours-per-week\": 40,\n",
      "  \"native-country\": \"United-States\",\n",
      "  \"loan_amount\": 0.0,\n",
      "  \"loan_approval_probability\": 0.495\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "2. What if customer 12762 had ALL these changes: Masters degree, capital-gain of 10000, and worked 45 hours per week in Exec-managerial? What would be the loan approval probability?\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"age\": 25,\n",
      "  \"workclass\": \"Private\",\n",
      "  \"fnlwgt\": 166977,\n",
      "  \"education\": \"Bachelors\",\n",
      "  \"education-num\": 13,\n",
      "  \"marital-status\": \"Married-civ-spouse\",\n",
      "  \"occupation\": \"Prof-specialty\",\n",
      "  \"relationship\": \"Wife\",\n",
      "  \"race\": \"White\",\n",
      "  \"sex\": \"Female\",\n",
      "  \"capital-gain\": 0,\n",
      "  \"capital-loss\": 1887,\n",
      "  \"hours-per-week\": 40,\n",
      "  \"native-country\": \"United-States\",\n",
      "  \"loan_amount\": 0.0,\n",
      "  \"loan_approval_probability\": 0.495\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "2. What if customer 12762 had ALL these changes: Masters degree, capital-gain of 10000, and worked 45 hours per week in Exec-managerial? What would be the loan approval probability?\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"scenario\": \"ALL changes: Masters degree, capital-gain of 10000, and worked 45 hours per week in Exec-managerial\",\n",
      "  \"modifications_applied\": [\"education=Masters\", \"capital-gain=10000\", \"hours-per-week=45.0\", \"occupation=Exec-managerial\"],\n",
      "  \"new_loan_approval_probability\": 0.24576203525066376,\n",
      "  \"baseline_loan_approval_probability\": 0.4946332275867462,\n",
      "  \"probability_change\": \"‚ÜòÔ∏è -24.9%\",\n",
      "  \"approved\": false\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "3. What is the maximum approved loan amount now?\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"scenario\": \"ALL changes: Masters degree, capital-gain of 10000, and worked 45 hours per week in Exec-managerial\",\n",
      "  \"modifications_applied\": [\"education=Masters\", \"capital-gain=10000\", \"hours-per-week=45.0\", \"occupation=Exec-managerial\"],\n",
      "  \"new_loan_approval_probability\": 0.24576203525066376,\n",
      "  \"baseline_loan_approval_probability\": 0.4946332275867462,\n",
      "  \"probability_change\": \"‚ÜòÔ∏è -24.9%\",\n",
      "  \"approved\": false\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "3. What is the maximum approved loan amount now?\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"maximum_approved_loan_amount\": 0.0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Response: {\n",
      "  \"customer_id\": 12762,\n",
      "  \"maximum_approved_loan_amount\": 0.0\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Privacy-Aware Loan Agent Demo\n",
    "\n",
    "demo_agent = PrivacyAwareLoanAgent(\n",
    "    model=model,\n",
    "    tools={\n",
    "        \"load_data\": load_data, \n",
    "        \"get_customer_information\": get_customer_information,\n",
    "        \"load_predict_loan_approval_propensity\": load_predict_loan_approval_propensity,\n",
    "        \"load_predict_loan_amount\": load_predict_loan_amount,\n",
    "        \"load_predict_loan_approval_whatif\": load_predict_loan_approval_whatif,\n",
    "        \"load_predict_loan_amount_whatif\": load_predict_loan_amount_whatif\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test the three key scenarios\n",
    "scenarios = [\n",
    "    \"Get information for customer 12762\",\n",
    "    \"What if customer 12762 had ALL these changes: Masters degree, capital-gain of 10000, and worked 45 hours per week in Exec-managerial? What would be the loan approval probability?\",\n",
    "    \"What is the maximum approved loan amount now?\"\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"\\n{i}. {scenario}\")\n",
    "    response = demo_agent.chat(scenario)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
